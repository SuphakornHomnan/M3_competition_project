fit = tslm(y ~ season, y)
plot(y= as.numeric(fit$model$y), x=as.numeric(fit$fitted.values),
xlab="Fitted", ylab= "Actuals")
plot(y= as.numeric(abs(fit$residuals/fit$model$y)), x=as.numeric(fit$fitted.values),
xlab="Fitted", ylab= "|Residuals|")
qqnorm(fit$residuals)
qqline(fit$residuals)
summary(fit)
fit = tslm(y ~ season, y)
summary(fit)
# plot residual diagnostic charts
plot(x= as.numeric(y), y=as.numeric(fit$residuals),
xlab="Value", ylab= "Residuals")
hist(fit$residuals, xlab="Residuals", prob=TRUE,
main="Histogram of the residuals")
lines(-80:80, dnorm(-80:80, 0, sd(fit$residuals)), col="red")
qqnorm(fit$residuals)
qqline(fit$residuals, col="red")
library(lmtest)
dwtest(fit) # p-value < 5%, accept hypothesis 0 (Not-Independance)
shapiro.test(fit$residuals) # p-value < 5%, accept hypothesis 0 (Not-normality)
bptest(fit) # p-value < 5%, accept hypothesis 0 (Heteroscedasticity)
fit = tslm(y ~ season, y)
summary(fit)
# plot residual diagnostic charts
plot(x= as.numeric(y), y=as.numeric(fit$residuals),
xlab="Value", ylab= "Residuals")
hist(fit$residuals, xlab="Residuals", prob=TRUE,
main="Histogram of the residuals")
lines(-80:80, dnorm(-80:80, 0, sd(as.numeric(fit$residuals)), col="red")
qqnorm(fit$residuals)
fit = tslm(y ~ season, y)
summary(fit)
# plot residual diagnostic charts
plot(x= as.numeric(y), y=as.numeric(fit$residuals),
xlab="Value", ylab= "Residuals")
hist(fit$residuals, xlab="Residuals", prob=TRUE,
main="Histogram of the residuals")
lines(-80:80, dnorm(-80:80, 0, sd(fit$residuals)), col="red")
qqnorm(fit$residuals)
qqline(fit$residuals, col="red")
library(lmtest)
dwtest(fit) # p-value < 5%, accept hypothesis 0 (Not-Independance)
shapiro.test(fit$residuals) # p-value < 5%, accept hypothesis 0 (Not-normality)
bptest(fit) # p-value < 5%, accept hypothesis 0 (Heteroscedasticity)
fit$residuals
sd(fit$residuals))
sd(fit$residuals)
fit = tslm(y ~ season, y)
summary(fit)
# plot residual diagnostic charts
plot(x= as.numeric(y), y=as.numeric(fit$residuals),
xlab="Value", ylab= "Residuals")
hist(fit$residuals, xlab="Residuals", prob=TRUE,
main="Histogram of the residuals")
lines(-80:80, dnorm(-80:80, 0, sd(fit$residuals), col="red")
qqnorm(fit$residuals)
fit = tslm(y ~ season, y)
summary(fit)
# plot residual diagnostic charts
plot(x= as.numeric(y), y=as.numeric(fit$residuals),
xlab="Value", ylab= "Residuals")
hist(fit$residuals, xlab="Residuals", prob=TRUE,
main="Histogram of the residuals")
lines(-80:80, dnorm(-80:80, 0, sd(fit$residuals), col="red"))
fit = tslm(y ~ season, y)
summary(fit)
# plot residual diagnostic charts
plot(x= as.numeric(y), y=as.numeric(fit$residuals),
xlab="Value", ylab= "Residuals")
hist(fit$residuals, xlab="Residuals", prob=TRUE,
main="Histogram of the residuals")
lines(-80:80, dnorm(-80:80, 0, sd(fit$residuals), col="red"))
fit = tslm(y ~ season, y)
summary(fit)
# plot residual diagnostic charts
plot(x= as.numeric(y), y=as.numeric(fit$residuals),
xlab="Value", ylab= "Residuals")
hist(fit$residuals, xlab="Residuals", prob=TRUE,
main="Histogram of the residuals")
lines(-80:80, dnorm(-80:80, 0, sd(fit$residuals)), col="red")
qqnorm(fit$residuals)
qqline(fit$residuals, col="red")
library(lmtest)
dwtest(fit) # p-value < 5%, accept hypothesis 0 (Not-Independance)
shapiro.test(fit$residuals) # p-value < 5%, accept hypothesis 0 (Not-normality)
bptest(fit) # p-value < 5%, accept hypothesis 0 (Heteroscedasticity)
fit = tslm(y ~ season, y)
summary(fit)
# plot residual diagnostic charts
plot(x= as.numeric(y), y=as.numeric(fit$residuals),
xlab="Value", ylab= "Residuals")
hist(fit$residuals, xlab="Residuals", prob=TRUE,
main="Histogram of the residuals")
qqnorm(fit$residuals)
qqline(fit$residuals, col="red")
library(lmtest)
dwtest(fit) # p-value < 5%, accept hypothesis 0 (Not-Independance)
shapiro.test(fit$residuals) # p-value < 5%, accept hypothesis 0 (Not-normality)
bptest(fit) # p-value < 5%, accept hypothesis 0 (Heteroscedasticity)
regression_fit = tslm(y ~ season, y)
summary(regression_fit)
# plot residual diagnostic charts
plot(x= as.numeric(y), y=as.numeric(regression_fit$residuals),
xlab="Value", ylab= "Residuals")
hist(regression_fit$residuals, xlab="Residuals", prob=TRUE,
main="Histogram of the residuals")
qqnorm(regression_fit$residuals)
qqline(regression_fit$residuals, col="red")
library(lmtest)
dwtest(regression_fit) # p-value < 5%, accept hypothesis 0 (Not-Independance)
shapiro.test(regression_fit$residuals) # p-value < 5%, accept hypothesis 0 (Not-normality)
bptest(regression_fit) # p-value < 5%, accept hypothesis 0 (Heteroscedasticity)
library(smooth)
ets_fit = es(y, model= "MNM")
plot(fit)
library(smooth)
ets_fit = es(y, model= "MNM")
plot(ets_fit)
forecast(regression_fit, h=18)
plot(forecast(regression_fit, h=18, level=c(80,90,95,99)))
plot(forecast(ets_fit, h=18, level=c(80,90,95,99)))
yout
y = M3[[1910]]$x
y_test = M3[[1910]]$xx
y_test
plot(forecast(regression_fit, h=18, level=c(80,90,95,99)))
plot(forecast(ets_fit, h=18))
library(smooth)
ets_smooth_fit = es(y, model= "MNM")
plot(ets_smooth_fit)
ets_fit = ets(y, model= "MNM", damped= FALSE)
plot(forecast(regression_fit, h=18, level=c(80,90,95,99)))
plot(forecast(ets_fit, h=18))
ets_fit = ets(y, model= "MNM", damped= FALSE)
plot(forecast(regression_fit, h=18, level=c(80,90,95,99)))
plot(forecast(ets_fit, h=18, level= c(80, 90, 95, 99)))
ets_fit = ets(y, model= "MNM", damped= FALSE)
plot(M3[[1509]])
plot(forecast(regression_fit, h=18, level=c(80,90,95,99)))
plot(forecast(ets_fit, h=18, level= c(80, 90, 95, 99)))
ets_fit = ets(y, model= "MNM", damped= FALSE)
plot(M3[[1910]])
plot(forecast(regression_fit, h=18, level=c(80,90,95,99)))
plot(forecast(ets_fit, h=18, level= c(80, 90, 95, 99)))
ets_fit = ets(y, model= "MNM", damped= FALSE)
plot(M3[[1910]], main= "Actual data")
plot(forecast(regression_fit, h=18, level=c(80,90,95,99)))
plot(forecast(ets_fit, h=18, level= c(80, 90, 95, 99)))
regression_fit
ets_fit = ets(y, model= "MNM", damped= FALSE)
plot(M3[[1910]], main= "Actual data")
plot(forecast(regression_fit, h=18, level=c(80,90,95,99)))
plot(forecast(ets_fit, h=18, level= c(80, 90, 95, 99)))
pool_model = list(regression_fit, ets_fit)
MAPE = array(NA, length(models))
for (i in 1:length(pool_model)) {
fcs <- forecast(pool_model[i], h=18)$mean
MAPE[i] = 100*mean(abs(y_test - fcs)/y_test)
}
pool_model
ets_fit = ets(y, model= "MNM", damped= FALSE)
plot(M3[[1910]], main= "Actual data")
plot(forecast(regression_fit, h=18, level=c(80,90,95,99)))
plot(forecast(ets_fit, h=18, level= c(80, 90, 95, 99)))
pool_model = list(regression_fit, ets_fit)
MAPE = array(NA, length(models))
for (i in 1:length(pool_model)) {
fcs <- forecast(pool_model[[i]], h=18)$mean
MAPE[i] = 100*mean(abs(y_test - fcs)/y_test)
}
MAPE
ets_fit = ets(y, model= "MNM", damped= FALSE)
plot(M3[[1910]], main= "Actual data")
plot(forecast(regression_fit, h=18, level=c(80,90,95,99)))
plot(forecast(ets_fit, h=18, level= c(80, 90, 95, 99)))
pool_model = list(regression_fit, ets_fit)
MAPE = array(NA, length(pool_model))
for (i in 1:length(pool_model)) {
fcs <- forecast(pool_model[[i]], h=18)$mean
MAPE[i] = 100*mean(abs(y_test - fcs)/y_test)
}
MAPE
fcs
ets_fit = ets(y, model= "MNM", damped= FALSE)
plot(M3[[1910]], main= "Actual data")
plot(forecast(regression_fit, h=18, level=c(80,90,95,99)))
plot(forecast(ets_fit, h=18, level= c(80, 90, 95, 99)))
pool_model = list(regression_fit, ets_fit)
MAPE = array(NA, length(pool_model))
for (i in 1:length(pool_model)) {
fcs <- forecast(pool_model[[i]], h=18)$mean
MAPE[i] = 100*mean(abs(y_test - fcs)/y_test)
}
MAPE
# Prepare arima pool models
p <- c(0,1,0,2)
d <- c(1,1,1,1)
q <- c(1,0,2,0)
P <- c(0,1,0,1)
D <- c(1,1,1,1)
Q <- c(1,0,1,0)
n_models <- 4
AICc <- array(NA, n_models)
for (m in 1:n_models){
fit <- Arima(yt, order=c(p[m],d[m],q[m]), seasonal=c(P[m],D[m],Q[m]))
AICc[m] <- round(fit$aicc,2)
}
library(Mcomp)
library(forecast)
y = M3[[1910]]$x
y_test = M3[[1910]]$xx
# Prepare arima pool models
p <- c(0,1,0,2)
d <- c(1,1,1,1)
q <- c(1,0,2,0)
P <- c(0,1,0,1)
D <- c(1,1,1,1)
Q <- c(1,0,1,0)
n_models <- 4
AICc <- array(NA, n_models)
for (m in 1:n_models){
fit <- Arima(yt, order=c(p[m],d[m],q[m]), seasonal=c(P[m],D[m],Q[m]))
AICc[m] <- round(fit$aicc,2)
}
bm <- which.min(AICc) # which is the best model?
arima_fit <- Arima(y, order=c(p[bm],d[bm],q[bm]), seasonal=c(P[bm],D[bm],Q[bm]))
summary(arima_fit)
tsdisplay(residuals(arima_fit))
Box.test(residuals(arima_fit), lag=h, fitdf=p[bm]+q[bm]+P[bm]+Q[bm])
# Prepare arima pool models
p <- c(0,1,0,2)
d <- c(1,1,1,1)
q <- c(1,0,2,0)
P <- c(0,1,0,1)
D <- c(1,1,1,1)
Q <- c(1,0,1,0)
n_models <- 4
AICc <- array(NA, n_models)
for (m in 1:n_models){
fit <- Arima(yt, order=c(p[m],d[m],q[m]), seasonal=c(P[m],D[m],Q[m]))
AICc[m] <- round(fit$aicc,2)
}
bm <- which.min(AICc) # which is the best model?
arima_fit <- Arima(y, order=c(p[bm],d[bm],q[bm]), seasonal=c(P[bm],D[bm],Q[bm]))
summary(arima_fit)
tsdisplay(residuals(arima_fit))
Box.test(residuals(arima_fit), lag=h, fitdf=p[bm]+q[bm]+P[bm]+Q[bm], type= "Box-Pierce")
plot(M3[[1910]], main= "Actual data")
plot(forecast(regression_fit, h=18, level=c(80,90,95,99)), main = "Forecast from trend-seasonality regression model")
plot(forecast(ets_fit, h=18, level= c(80, 90, 95, 99)))
plot(forecast(arima_fit, h=18, level= c(80, 90, 95, 99)))
pool_model = list(regression_fit, ets_fit, arima_fit)
MASE = array(NA, length(pool_model))
for (i in 1:length(pool_model)) {
fcs <- forecast(pool_model[[i]], h=18)$mean
mae <- mean(abs(y_test - fcs))
# in-sample mean absolute error (in-sample MAE)
in_sample_mae <- mean(abs(diff(y)))
MASE[i] <- round(mae / in_sample_mae,3)
}
MASE
plot(M3[[1910]], main= "Actual data")
regression_forecast <- forecast(regression_fit, h = 18, level = c(80, 90, 95, 99), intervals = "prediction")
plot(regression_forecast, main = "Forecast from trend-seasonality regression model", include = 100,
xlab = "Time", ylab = "Values")
# Add labels to the predictive intervals
legend("topright", legend = c("Point Forecast", "80% Prediction Interval", "90% Prediction Interval", "95% Prediction Interval", "99% Prediction Interval"),
col = c(1, 2, 2, 2, 2), lty = c(1, 2, 2, 2, 2), lwd = 2)
# Plot for ETS model
ets_forecast <- forecast(ets_fit, h = 18, level = c(80, 90, 95, 99), intervals = "prediction")
plot(ets_forecast, main = "Forecast from ETS model", include = 100, xlab = "Time", ylab = "Values")
# Add labels to the predictive intervals
legend("topright", legend = c("Point Forecast", "80% Prediction Interval", "90% Prediction Interval", "95% Prediction Interval", "99% Prediction Interval"),
col = c(1, 2, 2, 2, 2), lty = c(1, 2, 2, 2, 2), lwd = 2)
# Plot for ARIMA model
arima_forecast <- forecast(arima_fit, h = 18, level = c(80, 90, 95, 99), intervals = "prediction")
plot(arima_forecast, main = "Forecast from ARIMA model", include = 100, xlab = "Time", ylab = "Values")
# Add labels to the predictive intervals
legend("topright", legend = c("Point Forecast", "80% Prediction Interval", "90% Prediction Interval", "95% Prediction Interval", "99% Prediction Interval"),
col = c(1, 2, 2, 2, 2), lty = c(1, 2, 2, 2, 2), lwd = 2)
pool_model = list(regression_fit, ets_fit, arima_fit)
MASE = array(NA, length(pool_model))
for (i in 1:length(pool_model)) {
fcs <- forecast(pool_model[[i]], h=18)$mean
mae <- mean(abs(y_test - fcs))
# in-sample mean absolute error (in-sample MAE)
in_sample_mae <- mean(abs(diff(y)))
MASE[i] <- round(mae / in_sample_mae,3)
}
MASE
plot(M3[[1910]], main= "Actual data")
regression_forecast <- forecast(regression_fit, h = 18, level = c(80, 90, 95, 99), intervals = "prediction")
plot(regression_forecast, main = "Forecast from trend-seasonality regression model", include = 100,
xlab = "Time", ylab = "Values")
# Add labels to the predictive intervals with different colors
legend("topright", legend = c("Point Forecast", "80% Prediction Interval", "90% Prediction Interval", "95% Prediction Interval", "99% Prediction Interval"),
col = c("black", "blue", "green", "orange", "red"), lty = c(1, 1, 1, 1, 1), lwd = 2)
# Plot for ETS model
ets_forecast <- forecast(ets_fit, h = 18, level = c(80, 90, 95, 99), intervals = "prediction")
plot(ets_forecast, main = "Forecast from ETS model", include = 100, xlab = "Time", ylab = "Values")
# Add labels to the predictive intervals with different colors
legend("topright", legend = c("Point Forecast", "80% Prediction Interval", "90% Prediction Interval", "95% Prediction Interval", "99% Prediction Interval"),
col = c("black", "blue", "green", "orange", "red"), lty = c(1, 1, 1, 1, 1), lwd = 2)
# Plot for ARIMA model
arima_forecast <- forecast(arima_fit, h = 18, level = c(80, 90, 95, 99), intervals = "prediction")
plot(arima_forecast, main = "Forecast from ARIMA model", include = 100, xlab = "Time", ylab = "Values")
# Add labels to the predictive intervals with different colors
legend("topright", legend = c("Point Forecast", "80% Prediction Interval", "90% Prediction Interval", "95% Prediction Interval", "99% Prediction Interval"),
col = c("black", "blue", "green", "orange", "red"), lty = c(1, 1, 1, 1, 1), lwd = 2)
pool_model = list(regression_fit, ets_fit, arima_fit)
MASE = array(NA, length(pool_model))
for (i in 1:length(pool_model)) {
fcs <- forecast(pool_model[[i]], h=18)$mean
mae <- mean(abs(y_test - fcs))
# in-sample mean absolute error (in-sample MAE)
in_sample_mae <- mean(abs(diff(y)))
MASE[i] <- round(mae / in_sample_mae,3)
}
MASE
plot(M3[[1910]], main= "Actual data")
# Plot for regression model
regression_forecast <- forecast(regression_fit, h = 18, level = c(80, 90, 95, 99), intervals = "prediction")
plot(regression_forecast, main = "Forecast from trend-seasonality regression model", include = 100,
xlab = "Time", ylab = "Values")
# Add labels to the predictive intervals with different colors
legend("topright", legend = c("Point Forecast", "80%", "90%", "95%", "99%"),
col = c("black", "blue", "green", "orange", "red"), lty = c(1, 1, 1, 1, 1), lwd = 2)
# Plot for ETS model
ets_forecast <- forecast(ets_fit, h = 18, level = c(80, 90, 95, 99), intervals = "prediction")
plot(ets_forecast, main = "Forecast from ETS model", include = 100, xlab = "Time", ylab = "Values")
# Add labels to the predictive intervals with different colors
legend("topright", legend = c("Point Forecast", "80%", "90%", "95%", "99%"),
col = c("black", "blue", "green", "orange", "red"), lty = c(1, 1, 1, 1, 1), lwd = 2)
# Plot for ARIMA model
arima_forecast <- forecast(arima_fit, h = 18, level = c(80, 90, 95, 99), intervals = "prediction")
plot(arima_forecast, main = "Forecast from ARIMA model", include = 100, xlab = "Time", ylab = "Values")
# Add labels to the predictive intervals with different colors
legend("topright", legend = c("Point Forecast", "80%", "90%", "95%", "99%"),
col = c("black", "blue", "green", "orange", "red"), lty = c(1, 1, 1, 1, 1), lwd = 2)
pool_model = list(regression_fit, ets_fit, arima_fit)
MASE = array(NA, length(pool_model))
for (i in 1:length(pool_model)) {
fcs <- forecast(pool_model[[i]], h=18)$mean
mae <- mean(abs(y_test - fcs))
# in-sample mean absolute error (in-sample MAE)
in_sample_mae <- mean(abs(diff(y)))
MASE[i] <- round(mae / in_sample_mae,3)
}
MASE
plot(M3[[1910]], main= "Actual data")
plot(forecast(regression_fit, h=18, level=c(80,90,95,99)), main = "Forecast from trend-seasonality regression model")
plot(forecast(ets_fit, h=18, level= c(80, 90, 95, 99)))
plot(forecast(arima_fit, h=18, level= c(80, 90, 95, 99)))
pool_model = list(regression_fit, ets_fit, arima_fit)
MASE = array(NA, length(pool_model))
for (i in 1:length(pool_model)) {
fcs <- forecast(pool_model[[i]], h=18)$mean
mae <- mean(abs(y_test - fcs))
# in-sample mean absolute error (in-sample MAE)
in_sample_mae <- mean(abs(diff(y)))
MASE[i] <- round(mae / in_sample_mae,3)
}
MASE
auto.arima(y)
which.min(AICc)
c(p[bm],d[bm],q[bm])
c(P[bm],D[bm],Q[bm])
AICc
# Prepare arima pool models
p <- c(0,1,0,2)
d <- c(1,1,1,1)
q <- c(1,0,2,0)
P <- c(0,1,0,1)
D <- c(1,1,1,1)
Q <- c(1,0,1,0)
n_models <- 4
AICc <- array(NA, n_models)
for (m in 1:n_models){
fit <- Arima(yt, order=c(p[m],d[m],q[m]), seasonal=c(P[m],D[m],Q[m]))
AICc[m] <- round(fit$aicc,2)
}
bm <- which.min(AICc) # which is the best model?
arima_fit <- Arima(y, order=c(p[bm],d[bm],q[bm]), seasonal=c(P[bm],D[bm],Q[bm]))
summary(arima_fit)
tsdisplay(residuals(arima_fit))
Box.test(residuals(arima_fit), lag=h*2, fitdf=p[bm]+q[bm]+P[bm]+Q[bm], type= "Box-Pierce")
# Prepare arima pool models
p <- c(0,1,0,2)
d <- c(1,1,1,1)
q <- c(1,0,2,0)
P <- c(0,1,0,1)
D <- c(1,1,1,1)
Q <- c(1,0,1,0)
n_models <- 4
AICc <- array(NA, n_models)
for (m in 1:n_models){
fit <- Arima(yt, order=c(p[m],d[m],q[m]), seasonal=c(P[m],D[m],Q[m]))
AICc[m] <- round(fit$aicc,2)
}
bm <- which.min(AICc) # which is the best model?
arima_fit <- Arima(y, order=c(p[bm],d[bm],q[bm]), seasonal=c(P[bm],D[bm],Q[bm]))
summary(arima_fit)
tsdisplay(residuals(arima_fit))
Box.test(residuals(arima_fit), lag=h, fitdf=p[bm]+q[bm]+P[bm]+Q[bm], type= "Ljung-Box")
# Prepare arima pool models
p <- c(0,1,0,2)
d <- c(1,1,1,1)
q <- c(1,0,2,0)
P <- c(0,1,0,1)
D <- c(1,1,1,1)
Q <- c(1,0,1,0)
n_models <- 4
AICc <- array(NA, n_models)
for (m in 1:n_models){
fit <- Arima(yt, order=c(p[m],d[m],q[m]), seasonal=c(P[m],D[m],Q[m]))
AICc[m] <- round(fit$aicc,2)
}
bm <- which.min(AICc) # which is the best model?
arima_fit <- Arima(y, order=c(p[bm],d[bm],q[bm]), seasonal=c(P[bm],D[bm],Q[bm]))
summary(arima_fit)
tsdisplay(residuals(arima_fit))
Box.test(residuals(auto.arima(y)), lag=h, fitdf=p[bm]+q[bm]+P[bm]+Q[bm], type= "Ljung-Box")
plot(M3[[1910]], main= "Actual data")
plot(forecast(regression_fit, h=18, level=c(80,90,95,99)), main = "Forecast from trend-seasonality regression model")
plot(forecast(ets_fit, h=18, level= c(80, 90, 95, 99)))
plot(forecast(arima_fit, h=18, level= c(80, 90, 95, 99)))
pool_model = list(regression_fit, ets_fit, arima_fit)
MASE = array(NA, length(pool_model))
for (i in 1:length(pool_model)) {
fcs <- forecast(pool_model[[i]], h=18)$mean
mae <- mean(abs(y_test - fcs))
# in-sample mean absolute error (in-sample MAE)
in_sample_mae <- mean(abs(diff(y)))
MASE[i] <- round(mae / in_sample_mae,3)
}
MASE
model_selection_df
model_selection_df
library(forecast)
library(Mcomp)
library(foreach)
library(doSNOW)
time_start = Sys.time()
# Set the number of cores
cores <- 10
# Register the parallel backend
cl <- makeCluster(cores-1, type = "SOCK")
registerDoSNOW(cl)
# Initialize the MASE matrix
tsis <- seq(from=1509, 2499, by=10)
tsn <- length(tsis) # Amount time series data set
# Parallel foreach loop
result <- foreach (tsi = tsis, .combine = 'rbind', .packages = c('forecast', 'Mcomp')) %dopar% {
y <- M3[[tsi]]$x
h <- M3[[tsi]]$h
type <- M3[[tsi]]$type
origins = (length(y)/2):(length(y)-h)
MASE_ets = array(NA, length(origins))
MASE_arima = array(NA, length(origins))
i=1
for (origin in origins) {
yt = head(y, origin)
yv = y[(origin+1):(origin+h)]
fit_ets <- ets(yt, ic = "aicc")
fit_arima <- auto.arima(yt)
fcs_ets <- forecast(fit_ets, h = h)$mean
fcs_arima <- forecast(fit_arima, h=h)$mean
MASE_ets[i] = mean(abs(yv - fcs_ets)) / mean(abs(diff(yt, lag=12)))
MASE_arima[i] = mean(abs(yv - fcs_arima)) / mean(abs(diff(yt, lag=12)))
i = i + 1
}
mean_MASE_ets = mean(MASE_ets)
mean_MASE_arima = mean(MASE_arima)
return (
c(tsi, type, ifelse(mean_MASE_ets> mean_MASE_arima, round(mean_MASE_arima, 2), round( mean_MASE_ets, 2)),
ifelse(mean_MASE_ets> mean_MASE_arima, "arima", "ets"))
)
}
# Stop the parallel backend
stopCluster(cl)
# Extract the results
model_selection_df <- data.frame(result)
colnames(model_selection_df) <- c("Series_id", "Type", "MASE", "Choose")
# Print the result
print(model_selection_df)
Sys.time() - time_start
# 25.76 mins
library(openxlsx)
write.xlsx(model_selection_df, 'Excel/individual_model_selection.xlsx')
model_selection_df %>%
group_by(Choose) %>%
summarize(
amount = n()
)
library(dbplyr)
model_selection_df %>%
group_by(Choose) %>%
summarize(
amount = n()
)
model_selection_df %>%
group_by(Choose) %>%
summarize(
amount = n()
)
library(dplyr)
model_selection_df %>%
group_by(Choose) %>%
summarize(
amount = n()
)
