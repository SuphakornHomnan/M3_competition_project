## Explore and define selection model strategy

```{r}
library(forecast)
library(Mcomp)
library(foreach)
library(doSNOW)

time_start = Sys.time()

# Set the number of cores
cores <- 10

# Register the parallel backend
cl <- makeCluster(cores-1, type = "SOCK")
registerDoSNOW(cl)

# Initialize the MASE matrix
tsis <- seq(from=1509, 2499, by=10)
tsn <- length(tsis) # Amount time series data set

# Parallel foreach loop
result <- foreach (tsi = tsis, .combine = 'rbind', .packages = c('forecast', 'Mcomp')) %dopar% {
  y <- M3[[tsi]]$x

  h <- M3[[tsi]]$h
  type <- M3[[tsi]]$type
  
  origins = (length(y)/2):(length(y)-h)

  MASE_ets = array(NA, length(origins))
  MASE_arima = array(NA, length(origins))
  
  i=1
  for (origin in origins) {
    yt = head(y, origin)
    yv = y[(origin+1):(origin+h)]
    
    fit_ets <- ets(yt, ic = "aicc")
    fit_arima <- auto.arima(yt)
    
    fcs_ets <- forecast(fit_ets, h = h)$mean
    fcs_arima <- forecast(fit_arima, h=h)$mean
    
    MASE_ets[i] = mean(abs(yv - fcs_ets)) / mean(abs(diff(yt, lag=12)))
    MASE_arima[i] = mean(abs(yv - fcs_arima)) / mean(abs(diff(yt, lag=12)))
  
    i = i + 1
  }
  
  mean_MASE_ets = mean(MASE_ets)
  mean_MASE_arima = mean(MASE_arima)
  
  return (
    c(tsi, type, ifelse(mean_MASE_ets> mean_MASE_arima, round(mean_MASE_arima, 2), round( mean_MASE_ets, 2)),
      ifelse(mean_MASE_ets> mean_MASE_arima, "arima", "ets"))
    )
}

# Stop the parallel backend
stopCluster(cl)

# Extract the results
model_selection_df <- data.frame(result)

colnames(model_selection_df) <- c("Series_id", "Type", "MASE", "Choose")

# Print the result
print(model_selection_df)

Sys.time() - time_start
# 25.76 mins

library(dplyr)
model_selection_df %>%
  group_by(Choose) %>%
  summarize(
    amount = n()
  )
```

## Forecast h month future data, automatic ETS

```{r}
library(forecast)
library(Mcomp)
library(foreach)
library(doSNOW)

time_start = Sys.time()

# Set the number of cores
cores <- 10

# Register the parallel backend
cl <- makeCluster(cores-1, type = "SOCK")
registerDoSNOW(cl)

# Initialize the MASE matrix
tsis <- seq(from=1509, 2499, by=10)
tsn <- length(tsis) # Amount time series data set

# Parallel foreach loop
result <- foreach (tsi = tsis, .combine = 'rbind', .packages = c('forecast', 'Mcomp')) %dopar% {
  y <- M3[[tsi]]$x
  y_test <- M3[[tsi]]$xx
  type <- M3[[tsi]]$type
  h <- M3[[tsi]]$h
  
    
  fit <- ets(y)
    
  fcs <- forecast(fit, h = h)$mean
    
  MASE = round(mean(abs(y_test - fcs)) / mean(abs(diff(y, lag=12))), 2)
  sMAPE = round(mean((200*abs(y_test-fcs))/ (y_test+fcs)), 2)
  sMdAPE = round(median((200*abs(y_test-fcs))/ (y_test+fcs)), 2)
  
  # Determine trend
  isTrended <- ifelse(fit$components[2] != "N", "isTrended", "")
  
  # Determine seasonality
  isSeasonal <- ifelse(fit$components[3] != "N", "isSeasonal", "")
  
  # Choose only one value between "isTrended," "isSeasonal," or "Both"
  character <- ifelse(isTrended != "" & isSeasonal != "", "Both", paste(isTrended, isSeasonal, sep = ""))
  character <- ifelse(character == "", "NotTrendedNotSeasonal", character)
  
  return (
    c(tsi, type, character, MASE, sMAPE, sMdAPE)
    )
}

ets_different_ts <- data.frame(result)

colnames(ets_different_ts) <- c("Series_id", "Type", "Character", "MASE", "sMAPE", "sMdAPE")

round(Sys.time() - time_start, 2)
```

## Forecast h month future data, automatic ARIMA

```{r}
library(forecast)
library(Mcomp)
library(foreach)
library(doSNOW)

time_start = Sys.time()

# Set the number of cores
cores <- 10

# Register the parallel backend
cl <- makeCluster(cores-1, type = "SOCK")
registerDoSNOW(cl)

# Initialize the MASE matrix
tsis <- seq(from=1509, 2499, by=10)
tsn <- length(tsis) # Amount time series data set

# Parallel foreach loop
result <- foreach (tsi = tsis, .combine = 'rbind', .packages = c('forecast', 'Mcomp')) %dopar% {
  y <- M3[[tsi]]$x
  y_test <- M3[[tsi]]$xx
  type <- M3[[tsi]]$type
  h <- M3[[tsi]]$h
  
    
  fit <- auto.arima(y)
    
  fcs <- forecast(fit, h = h)$mean
  
  # Determine trend
  isTrended <- ifelse(fit$arma[6] != 0, "isTrended", "")
  
  # Determine seasonality
  isSeasonal <- ifelse(fit$arma[7] != 0, "isSeasonal", "")
  
  # Choose only one value between "isTrended," "isSeasonal," or "Both"
  character <- ifelse(isTrended != "" & isSeasonal != "", "Both", paste(isTrended, isSeasonal, sep = ""))
  character <- ifelse(character == "", "NotTrendedNotSeasonal", character)
    
  MASE = round(mean(abs(y_test - fcs)) / mean(abs(diff(y, lag=12))), 2)
  sMAPE = round(mean((200*abs(y_test-fcs))/ (y_test+fcs)), 2)
  sMdAPE = round(median((200*abs(y_test-fcs))/ (y_test+fcs)), 2)
  
  
  return (
    c(tsi, type, character, MASE, sMAPE, sMdAPE)
    )
}

arima_different_ts <- data.frame(result)

colnames(arima_different_ts) <- c("Series_id", "Type", "Character", "MASE", "sMAPE", "sMdAPE")

round(Sys.time() - time_start, 2)
```

## Forecast h month future data, Combination of ARIMA and ETS models (Model selection strategy)

```{r}
library(forecast)
library(Mcomp)
library(foreach)
library(doSNOW)

time_start = Sys.time()

# Set the number of cores
cores <- 10

# Register the parallel backend
cl <- makeCluster(cores-1, type = "SOCK")
registerDoSNOW(cl)

# Initialize the MASE matrix
tsis <- seq(from=1509, 2499, by=10)
tsn <- length(tsis) # Amount time series data set

i=1
# Parallel foreach loop
result <- foreach (tsi = tsis, .combine = 'rbind', .packages = c('forecast', 'Mcomp')) %dopar% {
  y <- M3[[tsi]]$x
  y_test <- M3[[tsi]]$xx
  type <- M3[[tsi]]$type
  h <- M3[[tsi]]$h
  
  if(model_selection_df$Choose[i] == "arima") {
    fit = auto.arima(y)
    
    # Determine trend
    isTrended <- ifelse(fit$arma[6] != 0, "isTrended", "")
  
    # Determine seasonality
    isSeasonal <- ifelse(fit$arma[7] != 0, "isSeasonal", "")
  } else {
    fit = ets(y)
    
    # Determine trend
    isTrended <- ifelse(fit$components[2] != "N", "isTrended", "")
    
    # Determine seasonality
    isSeasonal <- ifelse(fit$components[3] != "N", "isSeasonal", "")
  }
  
  fcs <- forecast(fit, h = h)$mean
  
  # Choose only one value between "isTrended," "isSeasonal," or "Both"
  character <- ifelse(isTrended != "" & isSeasonal != "", "Both", paste(isTrended, isSeasonal, sep = ""))
  character <- ifelse(character == "", "NotTrendedNotSeasonal", character)
  
  MASE = round(mean(abs(y_test - fcs)) / mean(abs(diff(y, lag=12))), 2)
  sMAPE = round(mean((200*abs(y_test-fcs))/ (y_test+fcs)), 2)
  sMdAPE = round(median((200*abs(y_test-fcs))/ (y_test+fcs)), 2)
  
  i= i+1
  return (
    c(tsi, type, character, MASE, sMAPE, sMdAPE)
    )
}

Comb_A_E_forecast <- data.frame(result)

colnames(Comb_A_E_forecast) <- c("Series_id", "Type", "Character", "MASE", "sMAPE", "sMdAPE")

round(Sys.time() - time_start, 2)
```

## Experiment Benchmark Method Accuracy Comparison

```{r}
library(forecast)
library(Mcomp)
library(foreach)
library(doSNOW)

time_start = Sys.time()

# Set the number of cores
cores <- 10

# Register the parallel backend
cl <- makeCluster(cores-1, type = "SOCK")
registerDoSNOW(cl)

# Initialize the MASE matrix
tsis <- seq(from=1509, 2499, by=10)
tsn <- length(tsis) # Amount time series data set

# Parallel foreach loop
result <- foreach (tsi = tsis, .combine = 'rbind', .packages = c('forecast', 'Mcomp')) %dopar% {
  y <- M3[[tsi]]$x
  y_test <- M3[[tsi]]$xx
  type <- M3[[tsi]]$type
  h <- M3[[tsi]]$h
  
  # Arima(yt, order=c(p[m],d[m],q[m]), seasonal=c(P[m],D[m],Q[m]))
  fit <- Arima(y, order=c(0,0,0), seasonal=c(0,1,0))
    
  fcs <- forecast(fit, h = h)$mean
    
  MASE = round(mean(abs(y_test - fcs)) / mean(abs(diff(y, lag=12))), 2)
  sMAPE = round(mean((200*abs(y_test-fcs))/ (y_test+fcs)), 2)
  sMdAPE = round(median((200*abs(y_test-fcs))/ (y_test+fcs)), 2)
  
  
  return (
    c(tsi, type, MASE, sMAPE, sMdAPE)
    )
}

arima_different_ts <- data.frame(result)

colnames(arima_different_ts) <- c("Series_id", "Type", "MASE", "sMAPE", "sMdAPE")

round(Sys.time() - time_start, 2)
```

## Analyse across different time series characteristics

```{r}
ets_different_ts %>%
  group_by(Character) %>%
  summarize(
    AVG_MASE = round(mean(as.numeric(MASE), na.rm = TRUE), 2),
    AVG_sMAPE = round(mean(as.numeric(sMAPE), na.rm = TRUE), 2),
    AVG_sMdAPE = round(mean(as.numeric(sMdAPE), na.rm = TRUE), 2)
  )

arima_different_ts %>%
  group_by(Character) %>%
  summarize(
    AVG_MASE = round(mean(as.numeric(MASE), na.rm = TRUE), 2),
    AVG_sMAPE = round(mean(as.numeric(sMAPE), na.rm = TRUE), 2),
    AVG_sMdAPE = round(mean(as.numeric(sMdAPE), na.rm = TRUE), 2)
  )

Comb_A_E_forecast %>%
  group_by(Character) %>%
  summarize(
    AVG_MASE = round(mean(as.numeric(MASE), na.rm = TRUE), 2),
    AVG_sMAPE = round(mean(as.numeric(sMAPE), na.rm = TRUE), 2),
    AVG_sMdAPE = round(mean(as.numeric(sMdAPE), na.rm = TRUE), 2)
  )
```

## Analyse across different time series types

```{r}
ets_forecast %>%
  group_by(Type) %>%
  summarize(
    AVG_MASE = round(mean(as.numeric(MASE), na.rm = TRUE), 2),
    AVG_sMAPE = round(mean(as.numeric(sMAPE), na.rm = TRUE), 2),
    AVG_sMdAPE = round(mean(as.numeric(sMdAPE), na.rm = TRUE), 2)
  )

arima_forecast %>%
  group_by(Type) %>%
  summarize(
    AVG_MASE = round(mean(as.numeric(MASE), na.rm = TRUE), 2),
    AVG_sMAPE = round(mean(as.numeric(sMAPE), na.rm = TRUE), 2),
    AVG_sMdAPE = round(mean(as.numeric(sMdAPE), na.rm = TRUE), 2)
  )

Comb_A_E_forecast %>%
  group_by(Type) %>%
  summarize(
    AVG_MASE = round(mean(as.numeric(MASE), na.rm = TRUE), 2),
    AVG_sMAPE = round(mean(as.numeric(sMAPE), na.rm = TRUE), 2),
    AVG_sMdAPE = round(mean(as.numeric(sMdAPE), na.rm = TRUE), 2)
  )

ets_forecast %>%
  group_by(Type) %>%
  summarise(Amount = n())
```

## Write data frame to excel file

```{r}
library(openxlsx)

write.xlsx(model_selection_df, 'Excel/individual_model_selection.xlsx')
```
